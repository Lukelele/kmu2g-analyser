{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/releases/LCG_102b/torchvision/0.12.0/x86_64-centos9-gcc11-opt/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /cvmfs/sft.cern.ch/lcg/releases/torchvision/0.12.0-2ee13/x86_64-centos9-gcc11-opt/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score, make_scorer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost\n",
    "\n",
    "import torch\n",
    "import beacon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "Data Loading and Visualisation\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KMU2GIB_EVENT_COUNT = 20000\n",
    "KMU2GSDINT_RATIO = 0.0419\n",
    "K2PI_RATIO = 33.3387\n",
    "KMU3_RATIO = 5.4048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (9, 6)\n",
    "# plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dir(directory):\n",
    "    # Initialize an empty list to store the dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Read the CSV file into a dataframe\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            try:\n",
    "                df = pd.read_csv(filepath)\n",
    "            except:\n",
    "                print(f'Error reading {filepath}')\n",
    "                continue\n",
    "            \n",
    "            # Append the dataframe to the list\n",
    "            dfs.append(df)\n",
    "\n",
    "    # Concatenate all dataframes into one\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading /eos/user/y/yuanye/Analysis/data/k2pidata/out1.csv\n",
      "Error reading /eos/user/y/yuanye/Analysis/data/k2pidata/out17.csv\n",
      "Error reading /eos/user/y/yuanye/Analysis/data/k2pidata/out18.csv\n",
      "Error reading /eos/user/y/yuanye/Analysis/data/k2pidata/out2.csv\n",
      "Error reading /eos/user/y/yuanye/Analysis/data/k2pidata/out21.csv\n",
      "Error reading /eos/user/y/yuanye/Analysis/data/k2pidata/out24.csv\n",
      "Error reading /eos/user/y/yuanye/Analysis/data/k2pidata/out3.csv\n",
      "Error reading /eos/user/y/yuanye/Analysis/data/k2pidata/out32.csv\n",
      "Error reading /eos/user/y/yuanye/Analysis/data/k2pidata/out4.csv\n",
      "Error reading /eos/user/y/yuanye/Analysis/data/k2pidata/out6.csv\n",
      "Error reading /eos/user/y/yuanye/Analysis/data/k2pidata/out9.csv\n"
     ]
    }
   ],
   "source": [
    "kmu2gib_df = read_dir(\"/eos/user/y/yuanye/Analysis/data/kmu2gibdata\")\n",
    "kmu2gsd_df = read_dir(\"/eos/user/y/yuanye/Analysis/data/kmu2gsddata\")\n",
    "kmu2gintm_df = read_dir(\"/eos/user/y/yuanye/Analysis/data/kmu2gintmdata\")\n",
    "k2pi_df = read_dir(\"/eos/user/y/yuanye/Analysis/data/k2pidata\")\n",
    "kmu3_df = read_dir(\"/eos/user/y/yuanye/Analysis/data/kmu3data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2pi_df['CumulativeEventCount'] = k2pi_df['EventCount'].cumsum()\n",
    "kmu3_df['CumulativeEventCount'] = kmu3_df['EventCount'].cumsum()\n",
    "kmu2gsd_df['CumulativeEventCount'] = kmu2gsd_df['EventCount'].cumsum()\n",
    "kmu2gintm_df['CumulativeEventCount'] = kmu2gintm_df['EventCount'].cumsum()\n",
    "kmu2gib_df['CumulativeEventCount'] = kmu2gib_df['EventCount'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490569, 7033119)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k2pi_df[\"CumulativeEventCount\"].max(), kmu3_df[\"CumulativeEventCount\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmu2gsd_df_sub = kmu2gsd_df[kmu2gsd_df[\"CumulativeEventCount\"] < KMU2GIB_EVENT_COUNT * (KMU2GSDINT_RATIO/2)]\n",
    "kmu2gintm_df_sub = kmu2gintm_df[kmu2gintm_df[\"CumulativeEventCount\"] < KMU2GIB_EVENT_COUNT * (KMU2GSDINT_RATIO/2)]\n",
    "kmu2gsdintm_df_sub = pd.concat([kmu2gsd_df_sub, kmu2gintm_df_sub], ignore_index=True)\n",
    "k2pi_df_sub = k2pi_df[k2pi_df[\"CumulativeEventCount\"] < KMU2GIB_EVENT_COUNT * K2PI_RATIO]\n",
    "kmu3_df_sub = kmu3_df[kmu3_df[\"CumulativeEventCount\"] < KMU2GIB_EVENT_COUNT * KMU3_RATIO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmu2gib Acceptance:  0.22035\n",
      "kmu2gsd- Acceptance:  0.20048055263553086\n",
      "kmu2gint- Acceptance:  0.20490367775831875\n",
      "k2pi Acceptance:  0.008956982199415122\n",
      "kmu3 Acceptance:  0.008213710019693964\n"
     ]
    }
   ],
   "source": [
    "# calculate the acceptance ratio\n",
    "kmu2gib_acceptance = len(kmu2gib_df) / KMU2GIB_EVENT_COUNT\n",
    "kmu2gsd_acceptance = len(kmu2gsd_df) / kmu2gsd_df[\"CumulativeEventCount\"].max()\n",
    "kmu2gintm_acceptance = len(kmu2gintm_df) / kmu2gintm_df[\"CumulativeEventCount\"].max()\n",
    "k2pi_acceptance = len(k2pi_df) / k2pi_df[\"CumulativeEventCount\"].max()\n",
    "kmu3_acceptance = len(kmu3_df) / kmu3_df[\"CumulativeEventCount\"].max()\n",
    "\n",
    "print(\"kmu2gib Acceptance: \", kmu2gib_acceptance)\n",
    "print(\"kmu2gsd- Acceptance: \", kmu2gsd_acceptance)\n",
    "print(\"kmu2gint- Acceptance: \", kmu2gintm_acceptance)\n",
    "print(\"k2pi Acceptance: \", k2pi_acceptance)\n",
    "print(\"kmu3 Acceptance: \", kmu3_acceptance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/yuanye/ipykernel_3654572/109178695.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  k2pi_df_sub[\"Mode\"] = 2\n",
      "/tmp/yuanye/ipykernel_3654572/109178695.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  kmu3_df_sub[\"Mode\"] = 3\n"
     ]
    }
   ],
   "source": [
    "# Add mode column for classification\n",
    "# 0: kmu2gib, 1: kmu2gsd, 2: kmu2gintm, 3: k2pi, 4: kmu3\n",
    "kmu2gib_df[\"Mode\"] = 0\n",
    "kmu2gsdintm_df_sub[\"Mode\"] = 1\n",
    "k2pi_df_sub[\"Mode\"] = 2\n",
    "kmu3_df_sub[\"Mode\"] = 3\n",
    "\n",
    "combined_df = pd.concat([kmu2gib_df, kmu2gsdintm_df_sub, k2pi_df_sub, kmu3_df_sub], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.insert(0, \"GTKMomentum\", np.sqrt(combined_df[\"GTKMomentumX\"]**2 + combined_df[\"GTKMomentumY\"]**2 + combined_df[\"GTKMomentumZ\"]**2))\n",
    "combined_df.insert(5, \"MuonMomentumPrime\", np.sqrt(combined_df[\"MuonMomentumPrimeX\"]**2 + combined_df[\"MuonMomentumPrimeY\"]**2 + combined_df[\"MuonMomentumPrimeZ\"]**2))\n",
    "combined_df.insert(10, \"MissingMomentum\", np.sqrt(combined_df[\"MissingMomentumX\"]**2 + combined_df[\"MissingMomentumY\"]**2 + combined_df[\"MissingMomentumZ\"]**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns for classification\n",
    "combined_df = combined_df.drop(columns=[\"NLKrCells\", \"NLKrClusters\", \"NVertices\", \"NTracks\", \"GTKMomentumX\", \"GTKMomentumY\", \"GTKMomentumZ\", \"GTKEnergy\", \"GTKGamma\", \"GTKBeta\", \"EventCount\", \"GTKMomentumX\", \"GTKMomentumY\", \"GTKMomentumZ\", \"MuonMomentumX\", \"MuonMomentumY\", \"MuonMomentumZ\", \"MuonMomentumPrimeX\", \"MuonMomentumPrimeY\", \"MuonMomentumPrimeZ\", \"MissingMomentumX\", \"MissingMomentumY\", \"MissingMomentumZ\", \"CDAAfterCut\", \"CumulativeEventCount\", \"CDA\", \"TrackTime\", \"QChi2Track\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_df.drop(columns=[\"Mode\"])\n",
    "y = combined_df[\"Mode\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "Machine Learning\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9079328314997105\n"
     ]
    }
   ],
   "source": [
    "y_pred_tree = dtree.predict(X_test)\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test, y_pred_tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     kmu2gib       0.90      0.93      0.92      1356\n",
      " kmu2gsdintm       0.11      0.14      0.12        36\n",
      "        k2pi       0.95      0.94      0.95      1805\n",
      "        kmu3       0.73      0.66      0.69       257\n",
      "\n",
      "    accuracy                           0.91      3454\n",
      "   macro avg       0.68      0.67      0.67      3454\n",
      "weighted avg       0.91      0.91      0.91      3454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred_tree, target_names=['kmu2gib', 'kmu2gsdintm', 'k2pi', 'kmu3'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9389114070642733\n"
     ]
    }
   ],
   "source": [
    "y_pred_forest = forest.predict(X_test)\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test, y_pred_forest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     kmu2gib       0.93      0.96      0.95      1356\n",
      " kmu2gsdintm       0.25      0.03      0.05        36\n",
      "        k2pi       0.96      0.97      0.97      1805\n",
      "        kmu3       0.79      0.69      0.74       257\n",
      "\n",
      "    accuracy                           0.94      3454\n",
      "   macro avg       0.73      0.66      0.68      3454\n",
      "weighted avg       0.93      0.94      0.93      3454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_forest, target_names=['kmu2gib', 'kmu2gsdintm', 'k2pi', 'kmu3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosted Decision Trees\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_tree = GradientBoostingClassifier(n_estimators=100)\n",
    "boosted_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9438332368268674\n"
     ]
    }
   ],
   "source": [
    "y_pred_boosted_tree = boosted_tree.predict(X_test)\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test, y_pred_boosted_tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     kmu2gib       0.94      0.96      0.95      1356\n",
      " kmu2gsdintm       0.25      0.08      0.12        36\n",
      "        k2pi       0.97      0.98      0.98      1805\n",
      "        kmu3       0.80      0.73      0.76       257\n",
      "\n",
      "    accuracy                           0.94      3454\n",
      "   macro avg       0.74      0.69      0.70      3454\n",
      "weighted avg       0.94      0.94      0.94      3454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_boosted_tree, target_names=['kmu2gib', 'kmu2gsdintm', 'k2pi', 'kmu3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extreme Gradient Boosting\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(objective='multi:softprob')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier(n_estimators=100)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9415170816444702\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb = xgb.predict(X_test)\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test, y_pred_xgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     kmu2gib       0.93      0.96      0.94      1356\n",
      " kmu2gsdintm       0.00      0.00      0.00        36\n",
      "        k2pi       0.97      0.98      0.97      1805\n",
      "        kmu3       0.83      0.72      0.77       257\n",
      "\n",
      "    accuracy                           0.94      3454\n",
      "   macro avg       0.68      0.67      0.67      3454\n",
      "weighted avg       0.93      0.94      0.94      3454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_xgb, target_names=['kmu2gib', 'kmu2gsdintm', 'k2pi', 'kmu3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Neural Networks\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8058, 17]), torch.Size([8058]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape, y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(beacon.Module):\n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(in_features, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 16)\n",
    "        self.fc4 = torch.nn.Linear(16, out_features)\n",
    "        self.dropout = torch.nn.Dropout(0.45)\n",
    "        self.classifier = torch.nn.Softmax(dim=1)\n",
    "        self.ReLU = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = DNN(X_train_tensor.shape[1], 4)\n",
    "dnn.compile(optimiser=torch.optim.SGD, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706d772aac674a28b6b9a302628b911c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.57 GiB of which 8.75 MiB is free. Process 2322271 has 14.14 GiB memory in use. Process 2518239 has 266.00 MiB memory in use. Including non-PyTorch memory, this process has 160.00 MiB memory in use. Of the allocated memory 16.60 MiB is allocated by PyTorch, and 9.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/yuanye/ipykernel_2503751/132403156.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/beacon/module.py\u001b[0m in \u001b[0;36mfit_tensor\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.57 GiB of which 8.75 MiB is free. Process 2322271 has 14.14 GiB memory in use. Process 2518239 has 266.00 MiB memory in use. Including non-PyTorch memory, this process has 160.00 MiB memory in use. Of the allocated memory 16.60 MiB is allocated by PyTorch, and 9.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "losses = dnn.fit_tensor(X_train_tensor, y_train_tensor, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dnn = dnn.predict(torch.tensor(X_test.values, dtype=torch.float32))\n",
    "y_pred_dnn = np.argmax(y_pred_dnn.cpu().numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7368479714667856"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
